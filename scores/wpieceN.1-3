['train.tsv', 'train_lower.tsv', 'train_lower_entities.tsv', 'valid.tsv', 'valid_lower.tsv', 'valid_lower_entities.tsv']
LinearSVC()
first instance as features: {'WP:_official': 1, 'WP:_death': 1, 'WP:_toll': 1, 'WP:_from': 1, 'WP:_#': 1, 'WP:_co': 1, 'WP:_##vid': 1, 'WP:_##19': 1, 'WP:_in': 1, 'WP:_the': 1, 'WP:_united': 1, 'WP:_kingdom': 1, 'WP:_is': 1, 'WP:_now': 1, 'WP:_greater': 1, 'WP:_than': 1, 'WP:_:': 3, 'WP:_german': 1, 'WP:_##y': 1, 'WP:_+': 9, 'WP:_pola': 1, 'WP:_##nd': 1, 'WP:_s': 2, 'WP:_##witz': 1, 'WP:_##erland': 1, 'WP:_aust': 1, 'WP:_##ria': 1, 'WP:_port': 1, 'WP:_##uga': 1, 'WP:_##l': 2, 'WP:_gr': 1, 'WP:_##ee': 1, 'WP:_##ce': 1, 'WP:_##wed': 1, 'WP:_##en': 1, 'WP:_fin': 1, 'WP:_##land': 1, 'WP:_nor': 1, 'WP:_##way': 1, 'WP:_ir': 1, 'WP:_##eland': 1, 'WP:_.': 5, 'WP:_combined': 1, 'WP:_uk': 1, 'WP:_67': 1, 'WP:_5': 1, 'WP:_million': 2, 'WP:_(': 2, 'WP:_233': 1, 'WP:_dead': 2, 'WP:_)': 2, 'WP:_above': 1, 'WP:_group': 1, 'WP:_185': 1, 'WP:_230': 1, 'WP:_http': 1, 'WP:_##ur': 1, 'WP:_official_death': 1, 'WP:_death_toll': 1, 'WP:_toll_from': 1, 'WP:_from_#': 1, 'WP:_#_co': 1, 'WP:_co_##vid': 1, 'WP:_##vid_##19': 1, 'WP:_##19_in': 1, 'WP:_in_the': 1, 'WP:_the_united': 1, 'WP:_united_kingdom': 1, 'WP:_kingdom_is': 1, 'WP:_is_now': 1, 'WP:_now_greater': 1, 'WP:_greater_than': 1, 'WP:_than_:': 1, 'WP:_:_german': 1, 'WP:_german_##y': 1, 'WP:_##y_+': 1, 'WP:_+_pola': 1, 'WP:_pola_##nd': 1, 'WP:_##nd_+': 1, 'WP:_+_s': 2, 'WP:_s_##witz': 1, 'WP:_##witz_##erland': 1, 'WP:_##erland_+': 1, 'WP:_+_aust': 1, 'WP:_aust_##ria': 1, 'WP:_##ria_+': 1, 'WP:_+_port': 1, 'WP:_port_##uga': 1, 'WP:_##uga_##l': 1, 'WP:_##l_+': 1, 'WP:_+_gr': 1, 'WP:_gr_##ee': 1, 'WP:_##ee_##ce': 1, 'WP:_##ce_+': 1, 'WP:_s_##wed': 1, 'WP:_##wed_##en': 1, 'WP:_##en_+': 1, 'WP:_+_fin': 1, 'WP:_fin_##land': 1, 'WP:_##land_+': 1, 'WP:_+_nor': 1, 'WP:_nor_##way': 1, 'WP:_##way_+': 1, 'WP:_+_ir': 1, 'WP:_ir_##eland': 1, 'WP:_##eland_.': 1, 'WP:_._.': 2, 'WP:_._combined': 1, 'WP:_combined_.': 1, 'WP:_._uk': 1, 'WP:_uk_:': 1, 'WP:_:_67': 1, 'WP:_67_.': 1, 'WP:_._5': 1, 'WP:_5_million': 1, 'WP:_million_(': 2, 'WP:_(_233': 1, 'WP:_233_dead': 1, 'WP:_dead_)': 2, 'WP:_)_above': 1, 'WP:_above_group': 1, 'WP:_group_:': 1, 'WP:_:_185': 1, 'WP:_185_million': 1, 'WP:_(_230': 1, 'WP:_230_dead': 1, 'WP:_)_http': 1, 'WP:_http_##ur': 1, 'WP:_##ur_##l': 1, 'WP:_official_death_toll': 1, 'WP:_death_toll_from': 1, 'WP:_toll_from_#': 1, 'WP:_from_#_co': 1, 'WP:_#_co_##vid': 1, 'WP:_co_##vid_##19': 1, 'WP:_##vid_##19_in': 1, 'WP:_##19_in_the': 1, 'WP:_in_the_united': 1, 'WP:_the_united_kingdom': 1, 'WP:_united_kingdom_is': 1, 'WP:_kingdom_is_now': 1, 'WP:_is_now_greater': 1, 'WP:_now_greater_than': 1, 'WP:_greater_than_:': 1, 'WP:_than_:_german': 1, 'WP:_:_german_##y': 1, 'WP:_german_##y_+': 1, 'WP:_##y_+_pola': 1, 'WP:_+_pola_##nd': 1, 'WP:_pola_##nd_+': 1, 'WP:_##nd_+_s': 1, 'WP:_+_s_##witz': 1, 'WP:_s_##witz_##erland': 1, 'WP:_##witz_##erland_+': 1, 'WP:_##erland_+_aust': 1, 'WP:_+_aust_##ria': 1, 'WP:_aust_##ria_+': 1, 'WP:_##ria_+_port': 1, 'WP:_+_port_##uga': 1, 'WP:_port_##uga_##l': 1, 'WP:_##uga_##l_+': 1, 'WP:_##l_+_gr': 1, 'WP:_+_gr_##ee': 1, 'WP:_gr_##ee_##ce': 1, 'WP:_##ee_##ce_+': 1, 'WP:_##ce_+_s': 1, 'WP:_+_s_##wed': 1, 'WP:_s_##wed_##en': 1, 'WP:_##wed_##en_+': 1, 'WP:_##en_+_fin': 1, 'WP:_+_fin_##land': 1, 'WP:_fin_##land_+': 1, 'WP:_##land_+_nor': 1, 'WP:_+_nor_##way': 1, 'WP:_nor_##way_+': 1, 'WP:_##way_+_ir': 1, 'WP:_+_ir_##eland': 1, 'WP:_ir_##eland_.': 1, 'WP:_##eland_._.': 1, 'WP:_._._.': 1, 'WP:_._._combined': 1, 'WP:_._combined_.': 1, 'WP:_combined_._uk': 1, 'WP:_._uk_:': 1, 'WP:_uk_:_67': 1, 'WP:_:_67_.': 1, 'WP:_67_._5': 1, 'WP:_._5_million': 1, 'WP:_5_million_(': 1, 'WP:_million_(_233': 1, 'WP:_(_233_dead': 1, 'WP:_233_dead_)': 1, 'WP:_dead_)_above': 1, 'WP:_)_above_group': 1, 'WP:_above_group_:': 1, 'WP:_group_:_185': 1, 'WP:_:_185_million': 1, 'WP:_185_million_(': 1, 'WP:_million_(_230': 1, 'WP:_(_230_dead': 1, 'WP:_230_dead_)': 1, 'WP:_dead_)_http': 1, 'WP:_)_http_##ur': 1, 'WP:_http_##ur_##l': 1}
Vocab size train:  408969
TfidfTransformer(sublinear_tf=True)
Vocab size:  408969
[0 1]
Classifier accuracy train: 99.99
===== dev set ====
Classifier: 82.50
              precision    recall  f1-score   support

           0     0.8349    0.8333    0.8341       528
           1     0.8140    0.8157    0.8148       472

    accuracy                         0.8250      1000
   macro avg     0.8244    0.8245    0.8245      1000
weighted avg     0.8250    0.8250    0.8250      1000

weighted f1: 82.5
accuracy: 82.5
